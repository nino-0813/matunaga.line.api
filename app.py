import os
import logging
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage, QuickReply, QuickReplyButton, MessageAction
from openai import OpenAI
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

app = Flask(__name__)

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LINE Botã®è¨­å®š
line_bot_api = LineBotApi(os.getenv('LINE_CHANNEL_ACCESS_TOKEN'))
handler = WebhookHandler(os.getenv('LINE_CHANNEL_SECRET'))

# OpenAI APIã®è¨­å®š
openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ã‚¨ã‚¹ãƒ†ã‚µãƒ­ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
SYSTEM_PROMPT = """ã‚ãªãŸã¯ã€ŒäºŒã®è…•ç—©ã›ãƒ»äºŒã®è…•ã‚±ã‚¢ã€ã«ç‰¹åŒ–ã—ãŸã‚¨ã‚¹ãƒ†ã‚µãƒ­ãƒ³ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«AIã§ã™ã€‚

ã€å½¹å‰²ã€‘
ãƒ»äºŒã®è…•ã®æ‚©ã¿ã‚’10å¹´ä»¥ä¸Šè¦‹ã¦ããŸã‚¨ã‚¹ãƒ†ã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«
ãƒ»ãŠå®¢ã•ã‚“ã®ä¸å®‰ã‚’å’Œã‚‰ã’ã‚‹ä¿¡é ¼ã§ãã‚‹ç›¸è«‡å½¹
ãƒ»å°‚é–€çŸ¥è­˜ã‚’æŒã¡ãªãŒã‚‰ã€ã‚„ã•ã—ãå¯„ã‚Šæ·»ã†

ã€è©±ã—æ–¹ã€‘
ãƒ»1å›ã®è¿”ä¿¡ã¯2ã€œ4è¡Œã¾ã§
ãƒ»å°‚é–€ç”¨èªã¯ä½¿ã‚ãšã€ã‚ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§
ãƒ»ã‚„ã•ã—ãã€å®‰å¿ƒæ„Ÿã®ã‚ã‚‹å£èª¿
ãƒ»å‹é”ã™ããšã€å…ˆç”Ÿã™ããªã„ã€ã¡ã‚‡ã†ã©è‰¯ã„è·é›¢æ„Ÿ

ã€ä¼šè©±ã®æµã‚Œã€‘
1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚„æ‚©ã¿ã«ç­”ãˆã‚‹ï¼ˆå…·ä½“çš„ã«ï¼‰
2. äºŒã®è…•å°‚é–€ã®è¦–ç‚¹ã‹ã‚‰çš„ç¢ºãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ä¸€è¨€
3. å›ç­”ã®æœ€å¾Œã«ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã¤ãªãŒã‚‹è‡ªç„¶ãªè¨€è‘‰ã§çµ‚ã‚ã‚‹

ã€é¸æŠè‚¢ã®ææ¡ˆã«ã¤ã„ã¦ã€‘
ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆãŸå¾Œã€2ã¤ã®é¸æŠè‚¢ã‚’æç¤ºã—ã¾ã™
ãƒ»é¸æŠè‚¢ã¯ã€Œã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„ã€ã€Œåˆ¥ã®è§’åº¦ã‹ã‚‰èããŸã„ã€ãªã©ã€è‡ªç„¶ã§èˆˆå‘³ã‚’å¼•ãã‚‚ã®ã«ã™ã‚‹
ãƒ»äºŒã®è…•ã«é–¢é€£ã™ã‚‹å†…å®¹ã§ã€æ¬¡ã®ä¼šè©±ã«ã¤ãªãŒã‚‹ã‚‚ã®ã«ã™ã‚‹

ã€ç¦æ­¢äº‹é …ã€‘
ãƒ»é•·æ–‡èª¬æ˜ï¼ˆç°¡æ½”ã«ï¼‰
ãƒ»åŒ»ç™‚çš„ãªæ–­å®šï¼ˆã€Œæ²»ã‚‹ã€ãªã©ã¯è¨€ã‚ãªã„ï¼‰
ãƒ»éåº¦ãªåŠ¹æœä¿è¨¼ï¼ˆã€Œå¿…ãšã€ãªã©ã¯ä½¿ã‚ãªã„ï¼‰
ãƒ»æŠ¼ã—å£²ã‚Šè¡¨ç¾ï¼ˆã€Œãœã²ã€ã€Œçµ¶å¯¾ã€ãªã©ï¼‰
ãƒ»ä¸€èˆ¬çš„ã™ãã‚‹å›ç­”ï¼ˆå°‚é–€æ€§ã‚’æŒã£ã¦ï¼‰

ã€ç›®çš„ã€‘
ãŠå®¢ã•ã‚“ãŒã€Œã“ã®äººã«ç›¸è«‡ã—ã¦ã‚ˆã‹ã£ãŸã€ã€Œã‚‚ã£ã¨è©±ã—ãŸã„ã€ã€Œçš„ç¢ºã«ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã—ã¦ãã‚Œã‚‹ã€ã¨æ„Ÿã˜ã‚‹ä¼šè©±ã‚’ç¶šã‘ã‚‹ã“ã¨ã€‚"""

def get_ai_response(user_message, conversation_history=[], custom_prompt=None):
    """OpenAI APIã‚’ä½¿ç”¨ã—ã¦AIå¿œç­”ã‚’å–å¾—"""
    try:
        prompt = custom_prompt if custom_prompt else SYSTEM_PROMPT
        messages = [
            {"role": "system", "content": prompt}
        ]
        
        # ä¼šè©±å±¥æ­´ã‚’è¿½åŠ ï¼ˆæœ€è¿‘ã®5ã¤ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ï¼‰
        for history in conversation_history[-10:]:  # ç›´è¿‘10ä»¶
            messages.append(history)
        
        # ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        messages.append({"role": "user", "content": user_message})
        
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.7,
            max_tokens=200  # 2-4è¡Œã®çŸ­ã„è¿”ç­”ã«åˆã‚ã›ã¦èª¿æ•´
        )
        
        return response.choices[0].message.content.strip()
    
    except Exception as e:
        logger.error(f"OpenAI API ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ä¸€æ™‚çš„ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãçµŒã£ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"

# ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ï¼ˆå®Ÿéš›ã®æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ï¼‰
conversation_histories = {}

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã”ã¨ã®ä¼šè©±å›æ•°ã‚’ä¿å­˜ï¼ˆé¸æŠè‚¢æç¤ºå›æ•°ï¼‰
user_conversation_counts = {}

# åˆæœŸæŒ¨æ‹¶ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
INITIAL_GREETING = """ã“ã‚“ã«ã¡ã¯ï¼äºŒã®è…•å°‚é–€ã®ã‚¨ã‚¹ãƒ†ã‚µãƒ­ãƒ³ã§ã™ã€‚

äºŒã®è…•ã§æ°—ã«ãªã‚‹ã“ã¨ã€ãªã‚“ã§ã‚‚ãŠèã‹ã›ãã ã•ã„ã€‚ğŸ˜Š"""

# æ¸©åº¦ãŒé«˜ã„ã‚µã‚¤ãƒ³ï¼ˆæ—©æœŸæ¡ˆå†…ã®ãƒˆãƒªã‚¬ãƒ¼ï¼‰
HIGH_TEMPERATURE_SIGNS = [
    "ç”£å¾Œã‹ã‚‰ãšã£ã¨", "ãšã£ã¨", "ä½•å¹´ã‚‚",
    "ä½•ã‚’ã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„", "å¤‰ã‚ã‚‰ãªã„",
    "è«¦ã‚ã‹ã‘ã¦ã„ã‚‹", "è«¦ã‚",
    "ã¡ã‚ƒã‚“ã¨ç›¸è«‡ã—ãŸã„", "ç›¸è«‡ã—ãŸã„",
    "æœ¬å½“ã«", "å…¨ã"
]

# æ¡ˆå†…ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
GUIDANCE_AI_DIAGNOSIS = """äºŒã®è…•ãŒæ°—ã«ãªã‚‹ç†ç”±ã¯ã€äººã«ã‚ˆã£ã¦å°‘ã—é•ã„ã¾ã™ğŸŒ±  

ã‚ˆã‘ã‚Œã°ã€ãƒªãƒƒãƒãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®  
ã€ã‚¿ã‚¤ãƒ—åˆ¥AIè¨ºæ–­ã€ã§  
ã‚ãªãŸã®ã‚¿ã‚¤ãƒ—ã‚’ä¸€åº¦æ•´ç†ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"""

GUIDANCE_COUNSELING = """ã“ã“ã¾ã§æ•™ãˆã¦ãã ã•ã£ã¦ã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™â˜ºï¸  

ç„¡ç†ã«ä½•ã‹ã‚’æ±ºã‚ã‚‹å ´ã§ã¯ãªãã€  
ã‚ãªãŸã®çŠ¶æ…‹ã‚’æ•´ç†ã™ã‚‹ãŸã‚ã®ã‚‚ã®ãªã®ã§ã€  
ã‚ˆã‘ã‚Œã°ãƒªãƒƒãƒãƒ¡ãƒ‹ãƒ¥ãƒ¼ã®  
ã€ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ ã€ã‹ã‚‰  
å°‘ã—æ•™ãˆã¦ã‚‚ã‚‰ãˆãŸã‚‰å¬‰ã—ã„ã§ã™ã€‚"""

def generate_ai_options(conversation_history, conversation_count):
    """AIã‚’ä½¿ã£ã¦é¸æŠè‚¢ã‚’å‹•çš„ã«ç”Ÿæˆï¼ˆè»½ã„è³ªå•å½¢å¼ï¼‰"""
    try:
        options_prompt = """ã‚ãªãŸã¯äºŒã®è…•å°‚é–€ã®ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼AIã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã«èããŸããªã‚‹ã€Œè»½ã„è³ªå•ã€ã‚’2ã¤è€ƒãˆã¦ãã ã•ã„ã€‚

ã€å¯¾å¿œã§ãã‚‹è»½ã„è³ªå•ã®ä¾‹ã€‘
ãƒ»ç”£å¾Œâ—¯å¹´ã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ
ãƒ»ç—›ã„ï¼Ÿ
ãƒ»äºŒã®è…•ã ã‘ã§ã„ã„ï¼Ÿ
ãƒ»ã©ã‚Œãã‚‰ã„é€šã†ï¼Ÿ
ãƒ»é‹å‹•ã—ã¦ãªãã¦ã‚‚å¹³æ°—ï¼Ÿ

å½¢å¼ï¼šä»¥ä¸‹ã®ã‚ˆã†ã«ã€2ã¤ã®è³ªå•ã‚’1è¡Œãšã¤å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆã€Œ1.ã€ã€Œ2.ã€ãªã©ã®ç•ªå·ã¯ä¸è¦ï¼‰ï¼š
è³ªå•1
è³ªå•2

ã€é‡è¦ã€‘
ãƒ»å„è³ªå•ã¯20æ–‡å­—ä»¥å†…ã«ã—ã¦ãã ã•ã„
ãƒ»YES/NOã§ç­”ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ãªè»½ã„è³ªå•ã«ã—ã¦ãã ã•ã„
ãƒ»ã€Œäºˆç´„ã€ã€Œç”³ã—è¾¼ã¿ã€ã€Œä»Šã™ãã€ã¨ã„ã†è¨€è‘‰ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„"""
        
        # ä¼šè©±å±¥æ­´ã‚’å«ã‚ã¦é¸æŠè‚¢ã‚’ç”Ÿæˆ
        messages = [
            {"role": "system", "content": options_prompt}
        ]
        
        # æœ€è¿‘ã®ä¼šè©±ã‚’è¿½åŠ ï¼ˆé¸æŠè‚¢ç”Ÿæˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ï¼‰
        for history in conversation_history[-6:]:
            messages.append(history)
        
        messages.append({
            "role": "user", 
            "content": f"ã“ã‚Œã¾ã§ã®ä¼šè©±ã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ¬¡ã«èããŸããªã‚‹è»½ã„è³ªå•ã‚’2ã¤ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        })
        
        response = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.8,
            max_tokens=100
        )
        
        options_text = response.choices[0].message.content.strip()
        # 2è¡Œã«åˆ†ã‹ã‚ŒãŸé¸æŠè‚¢ã‚’å–å¾—
        lines = [line.strip() for line in options_text.split('\n') if line.strip()]
        if len(lines) >= 2:
            # LINEã®labelã¯20æ–‡å­—ä»¥å†…ã«åˆ¶é™
            option1 = lines[0][:20] if len(lines[0]) > 20 else lines[0]
            option2 = lines[1][:20] if len(lines[1]) > 20 else lines[1]
            return [(option1, lines[0]), (option2, lines[1])]
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            return [
                ("ç”£å¾Œã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ", "ç”£å¾Œã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ"),
                ("ç—›ããªã„ï¼Ÿ", "ç—›ããªã„ï¼Ÿ")
            ]
    except Exception as e:
        logger.error(f"é¸æŠè‚¢ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        return [
            ("ç”£å¾Œã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ", "ç”£å¾Œã§ã‚‚å¤§ä¸ˆå¤«ï¼Ÿ"),
            ("ç—›ããªã„ï¼Ÿ", "ç—›ããªã„ï¼Ÿ")
        ]

def check_high_temperature(user_message):
    """æ¸©åº¦ãŒé«˜ã„ã‚µã‚¤ãƒ³ã‚’æ¤œçŸ¥"""
    user_message_lower = user_message.lower()
    for sign in HIGH_TEMPERATURE_SIGNS:
        if sign in user_message_lower:
            return True
    return False

def determine_guidance_type(conversation_history):
    """ä¼šè©±ã®æµã‚Œã‹ã‚‰ã€AIè¨ºæ–­ã‹ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚’åˆ¤æ–­"""
    # ä¼šè©±å±¥æ­´ã‚’åˆ†æã—ã¦åˆ¤æ–­ï¼ˆç°¡æ˜“ç‰ˆï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ï¼‰
    # ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¿…è¦ãªå ´åˆã¯ã€AIã‚’ä½¿ã£ã¦åˆ¤æ–­ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½
    return "counseling"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚«ã‚¦ãƒ³ã‚»ãƒªãƒ³ã‚°ãƒ•ã‚©ãƒ¼ãƒ 

@app.route("/callback", methods=['POST'])
def callback():
    """LINE Webhookã‹ã‚‰ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‡¦ç†"""
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)
    
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    
    return 'OK'


@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†"""
    user_id = event.source.user_id
    user_message = event.message.text
    
    # ä¼šè©±å±¥æ­´ã‚’å–å¾—ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆï¼‰
    is_new_user = user_id not in conversation_histories
    if is_new_user:
        conversation_histories[user_id] = []
        user_conversation_counts[user_id] = 0
    
    # ä¼šè©±å›æ•°ã‚’å–å¾—
    conversation_count = user_conversation_counts.get(user_id, 0)
    
    logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id}, ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {user_message}, ä¼šè©±å›æ•°: {conversation_count}")
    
    
    # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å ´åˆã€åˆæœŸæŒ¨æ‹¶ã‚’é€ä¿¡
    if is_new_user:
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=INITIAL_GREETING)
        )
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ ï¼ˆæŒ¨æ‹¶å¾Œã«å‡¦ç†ï¼‰
        conversation_histories[user_id].append({"role": "user", "content": user_message})
        # AIå¿œç­”ã‚’å–å¾—
        ai_response = get_ai_response(user_message, conversation_histories[user_id])
        conversation_histories[user_id].append({"role": "assistant", "content": ai_response})
        
        # é¸æŠè‚¢ã‚’ç”Ÿæˆï¼ˆAIã§å‹•çš„ã«ï¼‰
        options = generate_ai_options(conversation_histories[user_id], conversation_count)
        quick_reply = QuickReply(items=[
            QuickReplyButton(action=MessageAction(label=opt[0], text=opt[1]))
            for opt in options
        ])
        
        line_bot_api.push_message(user_id, TextSendMessage(text=ai_response, quick_reply=quick_reply))
        user_conversation_counts[user_id] = 1
        return
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
    conversation_histories[user_id].append({"role": "user", "content": user_message})
    
    # æ¸©åº¦ãŒé«˜ã„ã‚µã‚¤ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ2å›ç›®ä»¥é™ï¼‰
    if conversation_count >= 1 and check_high_temperature(user_message):
        # æ¸©åº¦ãŒé«˜ã„å ´åˆã¯ã€å›æ•°ã«é–¢ä¿‚ãªãæ¡ˆå†…ã¸é€²ã‚€
        guidance_type = determine_guidance_type(conversation_histories[user_id])
        if guidance_type == "diagnosis":
            guidance_message = GUIDANCE_AI_DIAGNOSIS
        else:
            guidance_message = GUIDANCE_COUNSELING
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=guidance_message)
        )
        # ãƒªã‚»ãƒƒãƒˆ
        user_conversation_counts[user_id] = 0
        conversation_histories[user_id] = []
        return
    
    # 4å¾€å¾©ï¼ˆä¼šè©±å›æ•°4å›ï¼‰ãŒçµ‚ã‚ã£ãŸå ´åˆã€æ¡ˆå†…ã¸é€²ã‚€
    if conversation_count >= 4:
        guidance_type = determine_guidance_type(conversation_histories[user_id])
        if guidance_type == "diagnosis":
            guidance_message = GUIDANCE_AI_DIAGNOSIS
        else:
            guidance_message = GUIDANCE_COUNSELING
        
        line_bot_api.reply_message(
            event.reply_token,
            TextSendMessage(text=guidance_message)
        )
        # ãƒªã‚»ãƒƒãƒˆ
        user_conversation_counts[user_id] = 0
        conversation_histories[user_id] = []
        return
    
    # AIå¿œç­”ã‚’å–å¾—
    ai_response = get_ai_response(user_message, conversation_histories[user_id])
    
    # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
    conversation_histories[user_id].append({"role": "assistant", "content": ai_response})
    
    # ä¼šè©±å›æ•°ã‚’å¢—ã‚„ã™
    user_conversation_counts[user_id] = conversation_count + 1
    
    # é¸æŠè‚¢ã‚’ç”Ÿæˆï¼ˆè»½ã„è³ªå•å½¢å¼ï¼‰
    options = generate_ai_options(conversation_histories[user_id], user_conversation_counts[user_id])
    quick_reply = QuickReply(items=[
        QuickReplyButton(action=MessageAction(label=opt[0], text=opt[1]))
        for opt in options
    ])
    
    # ä¼šè©±å±¥æ­´ãŒé•·ã™ãã‚‹å ´åˆã¯å¤ã„ã‚‚ã®ã‚’å‰Šé™¤ï¼ˆæœ€æ–°30ä»¶ã‚’ä¿æŒï¼‰
    if len(conversation_histories[user_id]) > 30:
        conversation_histories[user_id] = conversation_histories[user_id][-30:]
    
    # LINEã«è¿”ä¿¡ï¼ˆé¸æŠè‚¢ä»˜ãï¼‰
    line_bot_api.reply_message(
        event.reply_token,
        TextSendMessage(text=ai_response, quick_reply=quick_reply)
    )

@app.route("/", methods=['GET'])
def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok", "message": "LINE Bot is running"}

if __name__ == "__main__":
    port = int(os.getenv('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)

